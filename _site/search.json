[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DACSS603Final",
    "section": "",
    "text": "Code\nsource('dependencies.R')\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n\n\n\nResearch Questions\nThe Massachusetts Education Reform Act in 1993 was passed in the context of a national movement toward education reform throughout the United States. As early as 1989 there were calls to establish national curriculum standards as a way to improve student college and career readiness skills and close poverty gaps (Greer 2018). Massachusetts Comprehensive Assessment System (MCAS) tests were introduced as part of the Massachusetts Education Reform Act.\nThe MCAS tests are a significant tool for educational equity. Scores on the Grade 10 Math MCAS test “predict longer-term educational attainments and labor market success, above and beyond typical markers of student advantage. For example, among demographically similar students who attended the same high school and have the same level of ultimate educational attainment, those with higher MCAS mathematics scores go on to have much higher average earnings than those with lower scores.” (Papy 2020).\nWith the introduction of the new Common Core standards came the demand for appropriate curricular materials and teaching practices. Research indicates that the choice of instructional materials can have an impact “as large as or larger than the impact of teacher quality” (Chingos 2012). Massachusetts, along with Arkansas, Delaware, Kentucky, Louisiana, Maryland, Mississippi, Nebraska, New Mexico, Ohio, Rhode Island, Tennessee and Texas belongs to the Council of Chief State School Officers’ (CCSO), High Quality Instructional Materials and Professional Development network with the stated goal of ensuring that “Every student everyday is engaged in meaningful, affirming, grade-level instruction, by ensuring that every teacher has access to high-quality, standards aligned instructional materials and receives relevant professional development to support their use of these materials, and recently released a Case Study outlining progress and policy guidance for ensuring teachers and students have access to High Quality Instructional Materials.\nSince all Massachusetts students must pass a High School science MCAS and school’s receive annual reports on student performance on the MCAS exams, student performance reports could be leveraged to provide schools guidance on curricular areas to support.\nconsidering Next Generation MCAS High School Introductory Physics student performance data, we hope to address the following broad questions:\n\n\n\nIs there a relationship between differences in student performance across Science Practice Categories and student achievement?\nHow can trends in student performance be used to identify Introductory Physics content areas in need of curricular adjustments?\n\n\nIn this report, I will analyze the High School Introductory Physics Next Generation Massachusetts Comprehensive Assessment System (MCAS) tests results for Massachusetts public schools.\nThe HSPhy_NextGenMCASDF data frame contains performance results from 112 public schools across the commonwealth on the Next Generation High School Introductory Physics MCAS, which was administered in the Spring of 2022 and 2023.\nFor each school, there are values reported for 256 different variables which consist of information from two broad categories\n\nSchool Characteristics: This includes the name of the school and the size of the school as determined by the number of students that completed the MCAS exam.\nScience Practice and Reporting Category Performance Metrics: This includes the Category Possible Points, which summarizes the amount of points available on the exams from a given Reporting or Practice category, the school’s percentage of points earned on items associated with each Practice Category (A. Investigations and Questioning, B. Mathematics and Data, and C. Evidence, Reasoning, and Modeling ) and Reporting Category(MF (motion and forces) WA (waves), and EN (energy)). Details about the Science content and practice categories can be found in the the 2016 STE Massachusetts Curriculum Framework.\nAggregate Performance metrics: This includes a school’s percentage of students at each of the four Performance Levels, (E: Exceeding Expectations, M: Meeting Expectations, PM: Partially Meeting Expectations, and NM: Not Meeting Expectations), as well as a school’s Average Scaled Score.\nSchool-State Diff metrics: For each performance metric, the School-State Diff metric reports the difference between the percentage of points earned by students at a given school, School Percent Points and the percentage of available points earned by students in the state State Percent Points.\n\nSee the HSPhy_NextGenMCASDF data frame summary and codebook for further details.\nitem Possible Points.\nSummary Performance Metrics:\n\n\nHypothesis\n\n\n\nA school’s percent of student’s exceeding expectations on the Introductory Physics MCAS is negatively associated with variance in Mathematics and Data items.\nSchool’s mean performance diffs are not the same across science practice categories.\n\n\n\n\nDescriptive Statistics\n\n\nCode\n# HSPhy_NextGen_PerfDF\n# HSPhy_NextGen_SchoolIT301DF\n\n\n\n\nVisualization\n\n\n\n\n\n\n\n\n\n\nReferences\n\nChingos, & Whitehurst, M. M. 2012. “Choosing Blindly. Instructional Materials, Teacher Effectiveness, and the Common Core.” https://www.brookings.edu/wp-content/uploads/2016/06/0410_curriculum_chingos_whitehurst.pdf.\n\n\nGreer, W. 2018. “The 50 Year History of the Common Core.” The Journal of Educational Foundations 31 (3&4): 100–117. https://files.eric.ed.gov/fulltext/EJ1212104.pdf.\n\n\nPapy, Mantil, J. P. 2020. “Lifting All Boats? Accomplishments and Challenges from 20 Years of Education Reform in Massachusetts.” https://annenberg.brown.edu/sites/default/files/LiftingAllBoats_FINAL.pdf."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Codebook",
    "section": "",
    "text": "Code\n#source('dependencies.R')\n#knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n\n\nFor more information about the MCAS, see the Department of Elementary and Secondary Education’s (DESE) page.\n\n\n\nvariable\nMeasurement Level\nValues\n\n\n\n\nTested Students\nDiscrete\nnumber of students from a school that completed the MCAS assessment\n\n\nSchool Size\nOrdinal\nclassification of size of school based on number of students that completed the HS Physics MCAS exam\n\n\n\n\nSmall: 50 or less students\n\n\n\n\nMedium: 50-150\n\n\n\n\nLarge: More than 150\n\n\nPractice Category Pts\nDiscrete\nThe number of points available for items in a given scientific practice category\n\n\n\n\nEVR Pts: Evidence, Reasoning, and Modeling\n\n\n\n\nMD Pts: Mathematics and Data\n\n\n\n\nIQ Pts: Investigations and Questioning\n\n\nReporting Category Pts\nDiscrete\nThe number of points available for items in a given content area\n\n\n\n\nMF Pts: Motion and Forces\n\n\n\n\nWA Pts: Waves\n\n\n\n\nEN Pts: Energy\n\n\nSchool Percent Points\nContinuous\nPercent of points earned by Students at a school for all items in a given category\n\n\n\n\nMF% Pts: Motion and Forces\n\n\n\n\nWA% Pts: Waves\n\n\n\n\nEN% Pts: Energy\n\n\n\n\nEVR% Pts: Evidence, Reasoning, and Modeling\n\n\n\n\nMD% Pts: Mathematics and Data\n\n\n\n\nIQ% Pts: Investigations and Questioning\n\n\nSchool-State Diff\nDiscrete\nDifference between percent of points earned by given school’s students and points earned by students in MA for a given category.\n\n\n\n\nMF Diff: Motion and Forces\n\n\n\n\nWA Diff: Waves\n\n\n\n\nEN Diff: Energy\n\n\n\n\nEVR Diff: Evidence, Reasoning, and Modeling\n\n\n\n\nMD Diff: Mathematics and Data\n\n\n\n\nIQ Diff: Investigations and Questioning\n\n\nPerformance Level Count\nDiscrete\nThe number of student’s at a school at each performance level\n\n\n\n\nE Count: Exceeds Expectations\n\n\n\n\nM Count: Meets Expectations\n\n\n\n\nPM Count: Partially Meets Expectations\n\n\n\n\nNM Count Does Not Meet Expectations\n\n\nPerformance Level %\nDiscrete\nThe percent of student’s at a school at each performance level\n\n\n\n\nE%: Exceeds Expectations\n\n\n\n\nM%: Meets Expectations\n\n\n\n\nPM%: Partially Meets Expectations\n\n\n\n\nNM% Does Not Meet Expectations\n\n\nState Performance Level %\nDiscrete\nThe percent of student’s in MA at each performance level\n\n\n\n\nState E%: Exceeds Expectations\n\n\n\n\nState M%: Meets Expectations\n\n\n\n\nState PM%: Partially Meets Expectations\n\n\n\n\nState NM% Does Not Meet Expectations\n\n\nAvg. Scaled Score\nDiscrete\nThe school’s average scaled score\n\n\nState Avg. Scaled Score\nDiscrete\nThe average scaled score across all students in MA\n\n\nSchool Code\nNominal\nthe 8 digit identifier code for a school\n\n\nSchool Name\nNominal\nthe name of a school"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "(Knuth 1984) Chang, W. (2022). R Graphics Cookbook, 2nd Edition. O’Reilly Media.\nGrolemund, G., & Wickham, H. (2016). R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly Media.\nHighSchool Introductory Physics Item Report [Data] https://profiles.doe.mass.edu/mcas/mcasitems2.aspx?grade=HS&subjectcode=PHY&linkid=23&orgcode=04830000&fycode=2022&orgtypecode=5&\nH. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2009.\nPapay, J. P., Mantil, A., McDonough, A., Donahue, K., An, L., & Murnane, R. J. (n.d.). Lifting all boats? Accomplishments and Challenges from 20 Years of Education Reform in Massachusetts. Retrieved December 2, 2022, from https://annenberg.brown.edu/sites/default/files/LiftingAllBoats_FINAL.pdf\nR Core Team. (2020). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria.https://www.r-project.org.\nRStudio Team. (2019). RStudio: Integrated Development for R. RStudio, Inc., Boston, MA. https://www.rstudio.com.\nWickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). “Welcome to the tidyverse.” Journal of Open Source Software, 4(43), 1686. doi:10.21105/joss.01686 https://doi.org/10.21105/joss.01686.\n\n\n\n\n\n\nReferences\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "data_cleaning.html",
    "href": "data_cleaning.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\nsource('dependencies.R')"
  },
  {
    "objectID": "data_cleaning.html#state-item-analysis-report",
    "href": "data_cleaning.html#state-item-analysis-report",
    "title": "Data Cleaning",
    "section": "State Item Analysis Report",
    "text": "State Item Analysis Report\n\n\nCode\nHSPhy_2022_StateItemDF&lt;-read_state_item(\"data/2022_Physics_District_NextGenMCASItem.xlsx\", 2022, \"PHY\" )\n\nHSPhy_2022_StateItemDF\n\n\n\n\n  \n\n\n\nCode\nHSPhy_2023_StateItemDF&lt;-read_state_item(\"data/2023_Physics_District_NextGenMCASItem.xlsx\", 2023, \"PHY\" )\n\nHSPhy_2023_StateItemDF"
  },
  {
    "objectID": "data_cleaning.html#school-item-analysis-reports",
    "href": "data_cleaning.html#school-item-analysis-reports",
    "title": "Data Cleaning",
    "section": "School Item Analysis Reports",
    "text": "School Item Analysis Reports\n\n\nCode\nHSPhy_2022_SchoolItemDF&lt;-read_school_item(\"data/2022_Physics_NextGenMCASItem.xlsx\", 2022, \"PHY\")\nHSPhy_2022_SchoolItemDF\n\n\n\n\n  \n\n\n\nCode\nHSPhy_2022_SchoolItemDF&lt;-HSPhy_2022_SchoolItemDF%&gt;%\n  left_join(HSPhy_2022_StateItemDF, by= c('Year'='Year', 'Subject'='Subject', 'ITEM' = 'ITEM'))%&gt;%\n  mutate(`School-State Diff` = `School%`- `State%`)\nHSPhy_2022_SchoolItemDF\n\n\n\n\n  \n\n\n\nCode\nHSPhy_2023_SchoolItemDF&lt;-read_school_item(\"data/2023_Physics_NextGenMCASItem.xlsx\", 2023, \"PHY\")\nHSPhy_2023_SchoolItemDF\n\n\n\n\n  \n\n\n\nCode\nHSPhy_2023_SchoolItemDF&lt;-HSPhy_2023_SchoolItemDF%&gt;%\n  left_join(HSPhy_2023_StateItemDF, by= c('Year'='Year', 'Subject'='Subject', 'ITEM' = 'ITEM'))%&gt;%\n  mutate(`School-State Diff` = `School%`- `State%`)\n\nHSPhy_2023_SchoolItemDF\n\n\n\n\n  \n\n\n\nCode\ntail(HSPhy_2023_SchoolItemDF)\n\n\n\n\n  \n\n\n\nCode\ntail(HSPhy_2022_SchoolItemDF)\n\n\n\n\n  \n\n\n\nCode\nHSPhy_NextGen_SchoolItemDF &lt;- rbind(HSPhy_2022_SchoolItemDF, HSPhy_2023_SchoolItemDF)\n\nHSPhy_NextGen_SchoolItemDF"
  },
  {
    "objectID": "data_cleaning.html#state-nextgen-achievement-reports",
    "href": "data_cleaning.html#state-nextgen-achievement-reports",
    "title": "Data Cleaning",
    "section": "State NextGen Achievement Reports",
    "text": "State NextGen Achievement Reports\n\n\nCode\nHSPhy_2022_StateAchievementDF&lt;-read_state_achievement(\"data/2022_HSSci_NextGenMCAS.xlsx\", 2022, \"PHY\" )\nHSPhy_2022_StateAchievementDF\n\n\n\n\n  \n\n\n\nCode\nHSPhy_2023_StateAchievementDF&lt;-read_state_achievement(\"data/2023_HSSci_NextGenMCAS.xlsx\", 2023, \"PHY\" )\nHSPhy_2023_StateAchievementDF\n\n\n\n\n  \n\n\n\nCode\nHSPhy_NextGen_StateAchievementDF&lt;-rbind(HSPhy_2022_StateAchievementDF, HSPhy_2023_StateAchievementDF)\nHSPhy_NextGen_StateAchievementDF\n\n\n\n\n  \n\n\n\nCode\nlength(unique(HSPhy_NextGen_StateAchievementDF$`School Code`))\n\n\n[1] 112"
  },
  {
    "objectID": "data_cleaning.html#it301-reports",
    "href": "data_cleaning.html#it301-reports",
    "title": "Data Cleaning",
    "section": "IT301 Reports",
    "text": "IT301 Reports\n\n\nCode\nSG9_standardXWalk&lt;-read_excel(\"data/NextGenMCASItemxWalk.xlsx\", sheet = \"HS_Phys_StandardxWalk\")\n\nIT301_test&lt;-read_excel(\"data/2023_Physics_IT301 MCAS District and School Test Item Analysis Summary.xlsx\", skip = 14)\nIT301_test\n\n\n\n\n  \n\n\n\nCode\nIT301_2022&lt;-read_IT301(\"data/2022_Physics_IT301 MCAS District and School Test Item Analysis Summary.xlsx\", 2022, \"PHY\" )\nIT301_2022\n\n\n\n\n  \n\n\n\nCode\nIT301_2023&lt;-read_IT301(\"data/2023_Physics_IT301 MCAS District and School Test Item Analysis Summary.xlsx\", 2023, \"PHY\" )\nIT301_2023\n\n\n\n\n  \n\n\n\nCode\nNextGenIT301&lt;- rbind(IT301_2022, IT301_2023)\n\nHSPhy_NextGenIT301&lt;-NextGenIT301%&gt;%\n  left_join(SG9_standardXWalk, by = \"Standard\")\n\nHSPhy_NextGenIT301"
  },
  {
    "objectID": "data_cleaning.html#join-it301-reports-to-schoolitem-performance-reports",
    "href": "data_cleaning.html#join-it301-reports-to-schoolitem-performance-reports",
    "title": "Data Cleaning",
    "section": "Join IT301 reports to SchoolItem performance Reports",
    "text": "Join IT301 reports to SchoolItem performance Reports\n\n\nCode\nHSPhy_NextGen_SchoolIT301DF &lt;- left_join(HSPhy_NextGen_SchoolItemDF, HSPhy_NextGenIT301, by = c(\"Year\" = \"Year\", \"Subject\" = \"Subject\", \"ITEM\" = \"ITEM\"))\n\nHSPhy_NextGen_SchoolIT301DF"
  },
  {
    "objectID": "data_cleaning.html#compute-key-summary-stats-for-it301-reports",
    "href": "data_cleaning.html#compute-key-summary-stats-for-it301-reports",
    "title": "Data Cleaning",
    "section": "Compute Key Summary Stats for IT301 Reports",
    "text": "Compute Key Summary Stats for IT301 Reports\nData of 112 schools performance on Next Generation HS Introductory Physics exam in Spring of 2022 and Spring of 2023. 87 of those schools tested students in both years and 25 of those schools only tested students in 1 of the 2 testing years.\n\n\nCode\n## Compute % Earned by Practice Category\n## Compute State % Earned by Practice Category\n## Compute SD by Practice Category\n## Compute State % Earned by Reporting Category\n## Compute SD by Reporting Category\n\nPractice_Cat_Sum &lt;- HSPhy_NextGen_SchoolIT301DF%&gt;%\n  group_by(`Practice Category`)%&gt;%\n  summarise(`PC Mean Diff` = mean(`School-State Diff`),\n            `PC Med Diff` = median(`School-State Diff`),\n            `PC SD Diff` = sd(`School-State Diff`))\n\nPractice_Cat_Sum\n\n\n\n\n  \n\n\n\nCode\nPractice_Cat_School_Sum &lt;- HSPhy_NextGen_SchoolIT301DF%&gt;%\n  group_by(`School Name`,  `School Code`, `Practice Category`)%&gt;%\n  summarise(`PC Mean Diff` = mean(`School-State Diff`),\n            `PC Med Diff` = median(`School-State Diff`),\n            `PC SD Diff` = sd(`School-State Diff`))\n\nPractice_Cat_School_Sum\n\n\n\n\n  \n\n\n\nCode\nReporting_Cat_Sum &lt;- HSPhy_NextGen_SchoolIT301DF%&gt;%\n  group_by(`Reporting Category`)%&gt;%\n  summarise(`RC Mean Diff` = mean(`School-State Diff`),\n            `RC Med Diff` = median(`School-State Diff`),\n            `RC SD Diff` = sd(`School-State Diff`))\n\nReporting_Cat_Sum\n\n\n\n\n  \n\n\n\nCode\nReporting_Cat_School_Sum &lt;- HSPhy_NextGen_SchoolIT301DF%&gt;%\n  group_by(`School Name`,  `School Code`, `Reporting Category`)%&gt;%\n  summarise(`RC Mean Diff` = mean(`School-State Diff`),\n            `RC Med Diff` = median(`School-State Diff`),\n            `RC SD Diff` = sd(`School-State Diff`))\n\n\nReporting_Cat_School_Sum"
  },
  {
    "objectID": "data_cleaning.html#join-summary-stats-from-it301-reports-to-state-achievement-reports",
    "href": "data_cleaning.html#join-summary-stats-from-it301-reports-to-state-achievement-reports",
    "title": "Data Cleaning",
    "section": "Join Summary Stats from IT301 Reports to State Achievement Reports",
    "text": "Join Summary Stats from IT301 Reports to State Achievement Reports\n\n\nCode\n#HSPhy_NextGen_PerfDF&lt;- HSPhy_NextGen_StateAchievementDF%&gt;%\n#  select(`Year`, `Subject`, `School Code`, `Tested Students`, `Performance Level`, `Performance #Count`, `Performance%`, `State Performance%`, `Avg. Scaled Score`, `State Avg. Scaled Score`)%&gt;%\n#  left_join(HSPhy_NextGen_SchoolIT301DF, by = c(\"Year\" = \"Year\", \"Subject\" = \"Subject\", \"School #Code\" = \"School Code\", \"Tested Students\" = \"Tested Students\"))\n\n#HSPhy_NextGen_PerfDF%&gt;%\n#  select(`Year`, `School Name`, `School Code`, `Tested Students`)%&gt;%\n#  filter(`School Code` == \"04120530\")\n\n# HSPhy_NextGen_PerfDF%&gt;%\n#   mutate(`Tested` = max(`Tested Students.x`, `Tested Students.y`, na.rm = TRUE))%&gt;%\n#   mutate(`Tested Diff` = `Tested Students.x` - `Tested Students.y`)%&gt;%\n#   group_by(`School Name`)%&gt;%\n#   summarise(`Diff Sum` = sum(`Tested Diff`, na.rm = TRUE),\n#             `Tested` = sum(`Tested`))"
  },
  {
    "objectID": "data_cleaning.html#join-it301-summary-reports-to-schoolitem-performance-reports",
    "href": "data_cleaning.html#join-it301-summary-reports-to-schoolitem-performance-reports",
    "title": "Data Cleaning",
    "section": "Join IT301 Summary reports to SchoolItem performance Reports",
    "text": "Join IT301 Summary reports to SchoolItem performance Reports\n\n\nCode\nHSPhy_NextGen_SchoolIT301DF &lt;- left_join(HSPhy_NextGen_SchoolItemDF, HSPhy_NextGenIT301, by = c(\"Year\" = \"Year\", \"Subject\" = \"Subject\", \"ITEM\" = \"ITEM\"))\n\nHSPhy_NextGen_SchoolIT301DF\n\n\n\n\n  \n\n\n\nCode\nview(HSPhy_NextGen_SchoolIT301DF)\nlength(unique(HSPhy_NextGen_SchoolIT301DF$`School Name`))\n\n\n[1] 112"
  },
  {
    "objectID": "data_cleaning.html#state-e-below-average-with-practice-category",
    "href": "data_cleaning.html#state-e-below-average-with-practice-category",
    "title": "Data Cleaning",
    "section": "State E below average with Practice Category",
    "text": "State E below average with Practice Category\n\n\nCode\n# State E below average\nHSPhy_NextGen_StateAchievementDF\n\n\n\n\n  \n\n\n\nCode\nLowEStateDF&lt;- HSPhy_NextGen_StateAchievementDF%&gt;%\n  filter(`Performance Level` == \"E\")%&gt;%\n  filter(`Performance Diff` &lt; 0)%&gt;%\n  mutate(`ELow` = TRUE)\n\nLowEStateDF\n\n\n\n\n  \n\n\n\nCode\n#view(LowEStateDF)\n\nLowEPractice&lt;-LowEStateDF%&gt;%\n  select(`Year`, `Subject`, `School Code`, `Tested Students`, `Performance Level`, `Performance Count`, `Performance%`, `State Performance%`, `Performance Diff`, `Avg. Scaled Score`, `State Avg. Scaled Score`)%&gt;%\n  left_join(Practice_Cat_School_Sum, by = c( \"School Code\" = \"School Code\"))%&gt;%\n  select(`Year`, `School Name`, `School Code`, `Tested Students`, `Performance Level`, `Performance Count`, `Performance%`, `State Performance%`, `Performance Diff`, `Avg. Scaled Score`, \n         `State Avg. Scaled Score`, `Practice Category`, `PC Mean Diff`, `PC Med Diff`, `PC SD Diff`)\n\nLowEPractice%&gt;%\n  group_by(`Practice Category`)%&gt;%\n  summarise(`Low E PC Mean Diff` = mean(`PC Mean Diff`, na.rm = TRUE),\n            `Low E PC Med Diff` = median(`PC Med Diff`, na.rm = TRUE),\n            `Low E PC SD Diff` = sd(`PC SD Diff`, na.rm = TRUE)\n            )"
  },
  {
    "objectID": "data_cleaning.html#state-e-above-average-with-practice-category",
    "href": "data_cleaning.html#state-e-above-average-with-practice-category",
    "title": "Data Cleaning",
    "section": "State E above average with Practice Category",
    "text": "State E above average with Practice Category\n\n\nCode\nHSPhy_NextGen_StateAchievementDF\n\n\n\n\n  \n\n\n\nCode\nHighEStateDF&lt;- HSPhy_NextGen_StateAchievementDF%&gt;%\n  filter(`Performance Level` == \"E\")%&gt;%\n  filter(`Performance Diff` &gt; 0)%&gt;%\n  mutate(`ELow` = FALSE)\n\nHighEStateDF\n\n\n\n\n  \n\n\n\nCode\n#view(HighEStateDF)\n\nHighEPractice&lt;-HighEStateDF%&gt;%\n  select(`Year`, `Subject`, `School Code`, `Tested Students`, `Performance Level`, `Performance Count`, `Performance%`, `State Performance%`, `Performance Diff`, `Avg. Scaled Score`, `State Avg. Scaled Score`)%&gt;%\n  left_join(Practice_Cat_School_Sum, by = c( \"School Code\" = \"School Code\"))%&gt;%\n  select(`Year`, `School Name`, `School Code`, `Tested Students`, `Performance Level`, `Performance Count`, `Performance%`, `State Performance%`, `Performance Diff`, `Avg. Scaled Score`, \n         `State Avg. Scaled Score`, `Practice Category`, `PC Mean Diff`, `PC Med Diff`, `PC SD Diff`)\n\nHighEPractice%&gt;%\n  group_by(`Practice Category`)%&gt;%\n  summarise(`High E PC Mean Diff` = mean(`PC Mean Diff`, na.rm = TRUE),\n            `High E PC Med Diff` = median(`PC Med Diff`, na.rm = TRUE),\n            `High E PC SD Diff` = sd(`PC SD Diff`, na.rm = TRUE)\n            )"
  },
  {
    "objectID": "data_cleaning.html#state-e-and-m-above-average",
    "href": "data_cleaning.html#state-e-and-m-above-average",
    "title": "Data Cleaning",
    "section": "State E and M above average",
    "text": "State E and M above average\n\n\nCode\nHSPhy_NextGen_StateAchievementDF\n\n\n\n\n  \n\n\n\nCode\nHighMEStateDF&lt;- HSPhy_NextGen_StateAchievementDF%&gt;%\n  filter(`Performance Level` == \"E\" | `Performance Level` == \"M\")%&gt;%\n  filter(`Performance Diff` &gt; 0)%&gt;%\n  mutate(`MELow` = FALSE)\n\nHighMEStateDF\n\n\n\n\n  \n\n\n\nCode\n#view(HighEStateDF)\n\nHighMEPractice&lt;-HighMEStateDF%&gt;%\n  select(`Year`, `Subject`, `School Code`, `Tested Students`, `Performance Level`, `Performance Count`, `Performance%`, `State Performance%`, `Performance Diff`, `Avg. Scaled Score`, `State Avg. Scaled Score`)%&gt;%\n  left_join(Practice_Cat_School_Sum, by = c( \"School Code\" = \"School Code\"))%&gt;%\n  select(`Year`, `School Name`, `School Code`, `Tested Students`, `Performance Level`, `Performance Count`, `Performance%`, `State Performance%`, `Performance Diff`, `Avg. Scaled Score`, \n         `State Avg. Scaled Score`, `Practice Category`, `PC Mean Diff`, `PC Med Diff`, `PC SD Diff`)\n\nHighMEPractice%&gt;%\n  group_by(`Practice Category`)%&gt;%\n  summarise(`High ME PC Mean Diff` = mean(`PC Mean Diff`, na.rm = TRUE),\n            `High ME PC Med Diff` = median(`PC Med Diff`, na.rm = TRUE),\n            `High ME PC SD Diff` = sd(`PC SD Diff`, na.rm = TRUE)\n            )"
  },
  {
    "objectID": "data_cleaning.html#state-e-or-m-below-average",
    "href": "data_cleaning.html#state-e-or-m-below-average",
    "title": "Data Cleaning",
    "section": "State E or M below average",
    "text": "State E or M below average\n\n\nCode\nHSPhy_NextGen_StateAchievementDF\n\n\n\n\n  \n\n\n\nCode\nLowMEStateDF&lt;- HSPhy_NextGen_StateAchievementDF%&gt;%\n  filter(`Performance Level` == \"E\" | `Performance Level` == \"M\")%&gt;%\n  filter(`Performance Diff` &lt; 0)%&gt;%\n  mutate(`MELow` = FALSE)\n\nLowMEStateDF\n\n\n\n\n  \n\n\n\nCode\n#view(LowEStateDF)\n\nLowMEPractice&lt;-LowMEStateDF%&gt;%\n  select(`Year`, `Subject`, `School Code`, `Tested Students`, `Performance Level`, `Performance Count`, `Performance%`, `State Performance%`, `Performance Diff`, `Avg. Scaled Score`, `State Avg. Scaled Score`)%&gt;%\n  left_join(Practice_Cat_School_Sum, by = c( \"School Code\" = \"School Code\"))%&gt;%\n  select(`Year`, `School Name`, `School Code`, `Tested Students`, `Performance Level`, `Performance Count`, `Performance%`, `State Performance%`, `Performance Diff`, `Avg. Scaled Score`, \n         `State Avg. Scaled Score`, `Practice Category`, `PC Mean Diff`, `PC Med Diff`, `PC SD Diff`)\n\nLowMEPractice%&gt;%\n  group_by(`Practice Category`)%&gt;%\n  summarise(`Low ME PC Mean Diff` = mean(`PC Mean Diff`, na.rm = TRUE),\n            `Low ME PC Med Diff` = median(`PC Med Diff`, na.rm = TRUE),\n            `Low ME PC SD Diff` = sd(`PC SD Diff`, na.rm = TRUE)\n            )"
  },
  {
    "objectID": "data_cleaning.html#state-e-below-m-above",
    "href": "data_cleaning.html#state-e-below-m-above",
    "title": "Data Cleaning",
    "section": "State E below, M above",
    "text": "State E below, M above\n\n\nCode\nHSPhy_NextGen_StateAchievementDF\n\n\n\n\n  \n\n\n\nCode\nLowEHighMStateDF&lt;-HSPhy_NextGen_StateAchievementDF%&gt;%\n  mutate(`MHigh` = case_when(`Performance Level` == \"M\" & `Performance Diff` &gt;= 0 ~ TRUE,\n                             `Performance Level` == \"M\" & `Performance Diff` &lt; 0 ~ FALSE))%&gt;%\n  mutate(`ELow` = case_when(`Performance Level` == \"E\" & `Performance Diff` &lt; 0 ~ TRUE,\n                            `Performance Level` == \"E\" & `Performance Diff` &gt;= 0 ~ FALSE))%&gt;%\n  mutate(`EMOpp` = case_when(`MHigh` == TRUE && `ELow` == TRUE ~ TRUE))#%&gt;%\n  #filter(`EMOpp` == TRUE)#%&gt;%\n  #filter(`MHigh` == TRUE)\n  \n\nview(LowEHighMStateDF)"
  }
]